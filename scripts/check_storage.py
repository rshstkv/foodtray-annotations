#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å Storage –∏ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å –ë–î.

Usage:
    python3 scripts/check_storage.py              # –ü—Ä–æ–≤–µ—Ä–∫–∞
    python3 scripts/check_storage.py --fix        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
    python3 scripts/check_storage.py --detailed   # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç

Features:
- –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ Storage bucket
- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤, —Ä–∞–∑–º–µ—Ä, missing files)
- –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å –ë–î - –Ω–∞—Ö–æ–¥–∏—Ç –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
- –û–ø—Ü–∏—è --fix –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Set, List, Dict, Tuple
from dotenv import load_dotenv
from supabase import create_client
from tqdm import tqdm


def get_db_storage_paths(supabase_url: str, supabase_key: str) -> Set[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö storage_path –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    client = create_client(supabase_url, supabase_key)
    
    all_paths = set()
    page_size = 1000
    offset = 0
    
    print("üîç Fetching image paths from database...")
    
    while True:
        result = client.table('recognition_images')\
            .select('storage_path')\
            .range(offset, offset + page_size - 1)\
            .execute()
        
        if not result.data:
            break
        
        for row in result.data:
            all_paths.add(row['storage_path'])
        
        if len(result.data) < page_size:
            break
        
        offset += page_size
    
    return all_paths


def get_storage_files(supabase_url: str, supabase_key: str) -> Dict[str, int]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ Storage —Å –∏—Ö —Ä–∞–∑–º–µ—Ä–∞–º–∏."""
    client = create_client(supabase_url, supabase_key)
    
    files_dict = {}
    
    print("üîç Fetching files from Storage...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö "–ø–∞–ø–æ–∫" (recognition_id)
        folders = client.storage.from_('bbox-images').list()
        
        if not folders:
            return files_dict
        
        # –î–ª—è –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–∏ –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        for folder in tqdm(folders, desc="Scanning folders"):
            folder_name = folder.get('name', '')
            if not folder_name:
                continue
            
            try:
                files = client.storage.from_('bbox-images').list(path=folder_name)
                for file in files:
                    file_name = file.get('name', '')
                    file_size = file.get('metadata', {}).get('size', 0)
                    if file_name:
                        storage_path = f"{folder_name}/{file_name}"
                        files_dict[storage_path] = file_size
            except Exception as e:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å
                pass
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: Could not fully scan Storage: {e}")
    
    return files_dict


def find_local_files(dataset_dir: Path) -> Dict[str, Path]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    local_files = {}
    
    # –ù–∞—Ö–æ–¥–∏–º export –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    export_dir = None
    for item in dataset_dir.iterdir():
        if item.is_dir() and item.name.startswith('export_'):
            export_dir = item
            break
    
    if not export_dir:
        return local_files
    
    print(f"üîç Scanning local files in {export_dir}...")
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ recognition_* –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    recognition_dirs = [d for d in export_dir.iterdir() 
                       if d.is_dir() and d.name.startswith('recognition_')]
    
    for rec_dir in tqdm(recognition_dirs, desc="Scanning local"):
        photos_dir = rec_dir / "photos"
        if not photos_dir.exists():
            continue
        
        recognition_id = rec_dir.name.replace('recognition_', '')
        
        for img_file in photos_dir.glob('*.jpg'):
            storage_path = f"{recognition_id}/{img_file.name}"
            local_files[storage_path] = img_file
    
    return local_files


def format_size(size_bytes: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥."""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"


def main():
    parser = argparse.ArgumentParser(
        description='Check Storage integrity and find inconsistencies',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Check Storage status
  python3 scripts/check_storage.py
  
  # Check and fix missing files
  python3 scripts/check_storage.py --fix
  
  # Detailed report with file lists
  python3 scripts/check_storage.py --detailed
  
  # Check specific dataset path
  python3 scripts/check_storage.py --dataset-path /path/to/dataset
        """
    )
    parser.add_argument('--fix', action='store_true',
                       help='Automatically restore missing files')
    parser.add_argument('--detailed', action='store_true',
                       help='Show detailed report with file lists')
    parser.add_argument('--dataset-path', type=str, default=None,
                       help='Path to dataset directory')
    parser.add_argument('--show-missing', action='store_true',
                       help='Show list of missing files')
    
    args = parser.parse_args()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º .env.local
    load_dotenv('.env.local')
    
    supabase_url = os.getenv('SUPABASE_URL') or os.getenv('NEXT_PUBLIC_SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY') or os.getenv('SUPABASE_ANON_KEY')
    
    if not supabase_url or not supabase_key:
        print("‚ùå Supabase credentials not found in .env.local")
        sys.exit(1)
    
    print()
    print("="*60)
    print("üîç STORAGE INTEGRITY CHECK")
    print("="*60)
    print()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
    db_paths = get_db_storage_paths(supabase_url, supabase_key)
    print(f"‚úÖ Found {len(db_paths)} image records in database")
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Storage
    storage_files = get_storage_files(supabase_url, supabase_key)
    print(f"‚úÖ Found {len(storage_files)} files in Storage")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    missing_in_storage = db_paths - set(storage_files.keys())
    extra_in_storage = set(storage_files.keys()) - db_paths
    
    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä
    total_size = sum(storage_files.values())
    
    print()
    print("="*60)
    print("üìä STATISTICS")
    print("="*60)
    print(f"Database records:     {len(db_paths)}")
    print(f"Storage files:        {len(storage_files)}")
    print(f"Storage size:         {format_size(total_size)}")
    print()
    print(f"‚úÖ Files in sync:      {len(db_paths) - len(missing_in_storage)}")
    print(f"‚ö†Ô∏è  Missing in Storage: {len(missing_in_storage)}")
    print(f"‚ö†Ô∏è  Extra in Storage:   {len(extra_in_storage)}")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    if args.detailed or args.show_missing:
        if missing_in_storage:
            print()
            print("="*60)
            print("‚ö†Ô∏è  MISSING FILES IN STORAGE")
            print("="*60)
            for path in sorted(list(missing_in_storage)[:20]):
                print(f"  - {path}")
            if len(missing_in_storage) > 20:
                print(f"  ... and {len(missing_in_storage) - 20} more")
        
        if extra_in_storage and args.detailed:
            print()
            print("="*60)
            print("‚ö†Ô∏è  EXTRA FILES IN STORAGE (not in DB)")
            print("="*60)
            for path in sorted(list(extra_in_storage)[:20]):
                print(f"  - {path}")
            if len(extra_in_storage) > 20:
                print(f"  ... and {len(extra_in_storage) - 20} more")
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
    if args.fix and missing_in_storage:
        print()
        print("="*60)
        print("üîß RESTORING MISSING FILES")
        print("="*60)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
        if args.dataset_path:
            dataset_dir = Path(args.dataset_path)
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            try:
                script_dir = Path(__file__).parent
                config_file = script_dir / "db_config.json"
                if config_file.exists():
                    with open(config_file, 'r') as f:
                        config = json.load(f)
                        dataset_dir = Path(config['dataset_paths']['default_dataset_dir'])
                else:
                    dataset_dir = Path("/Users/romanshestakov/Downloads/RRS_Dataset 2")
            except Exception:
                dataset_dir = Path("/Users/romanshestakov/Downloads/RRS_Dataset 2")
        
        if not dataset_dir.exists():
            print(f"‚ùå Dataset directory not found: {dataset_dir}")
            print("   Use --dataset-path to specify the correct path")
            sys.exit(1)
        
        # –ù–∞—Ö–æ–¥–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
        local_files = find_local_files(dataset_dir)
        print(f"‚úÖ Found {len(local_files)} local files")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –º–æ–∂–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
        restorable = []
        for path in missing_in_storage:
            if path in local_files:
                restorable.append((path, local_files[path]))
        
        print(f"üì§ Can restore {len(restorable)} / {len(missing_in_storage)} missing files")
        
        if restorable:
            confirmation = input(f"\nUpload {len(restorable)} files? (yes/no): ").strip().lower()
            if confirmation == 'yes':
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º upload_images_only.py —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
                print("\nüöÄ Starting upload...")
                print(f"   Run: python3 scripts/upload_images_only.py --dataset-path {dataset_dir}")
                print()
                print("   Or use the optimized command:")
                print(f"   npm run db:restore:quick")
    
    print()
    print("="*60)
    
    # –ò—Ç–æ–≥
    if not missing_in_storage and not extra_in_storage:
        print("‚úÖ STORAGE IS IN PERFECT SYNC WITH DATABASE!")
    elif missing_in_storage:
        print("‚ö†Ô∏è  ACTION REQUIRED: Missing files in Storage")
        print(f"   Run with --fix to restore missing files")
    else:
        print("‚úÖ All database files are present in Storage")
    
    print("="*60)
    print()


if __name__ == '__main__':
    main()


